------------------------------------------------------------------------

title: "Arrival At Carcasses" author: "Kaija Gahm" date: "2022-10-10" output: html_document editor_options: markdown: wrap: sentence

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r include = F}
library(tidyverse)
library(vultureUtils)
library(igraph)
library(elevatr) # for getting elevation data
library(suncalc) # for calculating sunrise and sunset
library(ggmap)
source("bboxFromRad.R")
library(units)
library(tidyverse)
library(sf)
library(gganimate)
library(rnaturalearth)
library(gifski)
```

```{r}
datAnnot <- feather::read_feather("data/datAnnot.feather")
```

# Analyzing arrival order at carcasses

## IDENTIFY FEEDING EVENTS

Let's move on to examining an individual's movement patterns to identify arrival at a carcass site. Going to pick the individual with the longest run:

```{r}
targetIndiv <- unique(datAnnot$trackId[datAnnot$longestRun == max(datAnnot$longestRun)])
track <- datAnnot %>%
  filter(trackId == targetIndiv)

trackDays <- track %>%
  group_by(dateOnly) %>%
  group_split(.keep = TRUE)
```

```{r}
randomDay <- sample(1:length(trackDays), size = 1)
```

### Relative altitude

In order for an analysis of speed and altitude to make any sense at all, we need to cross-reference these measurements with elevation data for Israel. We can obtain this using the `elevatr` package.

```{r include = F}
# Add sunrise and sunset information using suncalc
## first let's get the mean lat and long for the current track
meanLat <- mean(track$location_lat)
meanLong <- mean(track$location_long)
dates <- seq(from = min(track$dateOnly), to = max(track$dateOnly), by = "1 day")
sunriseSunset <- suncalc::getSunlightTimes(date = dates, lat = meanLat, lon = meanLong, keep = c("sunrise", "sunset")) %>%
  dplyr::select("dateOnly" = date, sunrise, sunset)
track <- track %>%
  left_join(sunriseSunset, by = "dateOnly")

# Make it an sf object and add elevation
trackSF <- track %>%
  sf::st_as_sf(., coords = c("location_long", "location_lat"), crs = "WGS84")
elevs <- elevatr::get_elev_raster(trackSF, z = 10) 
trackSF$groundElev <- raster::extract(x = elevs, y = trackSF)
trackSF <- trackSF %>%
  mutate(height_above_ground = height_above_msl - groundElev)

# let's set anything below 0 to 0.
trackSF <- trackSF %>%
  mutate(height_above_ground = case_when(height_above_ground < 0 ~ 0,
                                         TRUE ~ height_above_ground))

trackDaysSF <- trackSF %>%
  group_by(dateOnly) %>%
  group_split(.keep = TRUE)
```

#### Speed/relative altitude plots

Now let's re-do the speed and altitude plots, using altitude above ground:

```{r}
# create rectangles to add to ggplot, assuming the dataset has the "sunrise" and "sunset" and "timestamp" columns.
sunriseSunsetBars <- list(geom_rect(aes(xmin = min(timestamp),
                                        xmax = min(sunrise),
                                        ymin = -Inf,
                                        ymax = Inf), alpha = 0.003),
                          geom_rect(aes(xmin = max(sunset),
                                        xmax = max(timestamp),
                                        ymin = -Inf,
                                        ymax = Inf), alpha = 0.003))

randomDay <- sample(1:length(trackDaysSF), size = 1)

altitude <- trackDaysSF[[randomDay]] %>%
  mutate(height_above_msl = case_when(height_above_msl < groundElev ~ groundElev,
                                      TRUE ~ height_above_msl)) %>%
  ggplot(aes(x = timestamp, y = height_above_msl))+
  geom_area(aes(y = groundElev), fill = "#996633")+
  geom_line(alpha = 0.5)+
  geom_point(aes(col = ground_speed), size = 3)+
  scale_color_viridis_c()+
  ylab("Elevation (m)")+
  xlab("Time")+
  theme_minimal()+
  sunriseSunsetBars
altitude
```

## KNOWN FEEDING EVENTS

### Feeding event data

Read in the feeding event data (this is the most updated version we have; should work on getting more info from more recent feeding events.)

#### Sunrise/sunset, day/night to datAnnot

```{r include = F}
# using the mean values of lat and long for this dataset, which may not be perfect but it's fairly decent.
meanLat <- mean(datAnnot$location_lat)
meanLong <- mean(datAnnot$location_long)

# Add sunrise/sunset information for each day, and use it to calculate whether each point takes place during day or night.
sunriseSunset <- suncalc::getSunlightTimes(date = unique(datAnnot$dateOnly), lat = meanLat, lon = meanLong, keep = c("sunrise", "sunset")) %>%
  dplyr::select("dateOnly" = date, sunrise, sunset)

sunsetSunrise <- sunriseSunset %>%
  dplyr::select(sunset, sunrise) %>%
  mutate(sunrise = lead(sunrise))

datAnnot <- datAnnot %>%
  left_join(sunriseSunset, by = "dateOnly") %>%
  mutate(dayNight = case_when(timestamp >= sunrise & timestamp <= sunset ~ "day",
                              TRUE ~ "night")) %>%
  dplyr::select(-c("sunrise", "sunset")) %>%
  mutate(dayNight = factor(dayNight))
```

```{r}
feedEvents <- read.csv("data/feeding_station_south_data.xlsx - Sheet1.csv")
# add datetime
feedEvents <- feedEvents %>%
  mutate(datetime = lubridate::mdy_hms(Timestamp)) %>%
  dplyr::select(-Timestamp)

# Subset to only include feeding events that occurred within the time range of this dataset
min <- min(datAnnot$timestamp)
max <- max(datAnnot$timestamp)
feedEvents <- feedEvents %>%
  filter(datetime >= min & datetime <= max)
nrow(feedEvents)
head(feedEvents)
table(feedEvents$area)
```

### Feeding station locations

Now that we have that data, we critically need access to the feeding station location data so that we can match these carcass drops to lat/long.

```{r include = F}
feedingStations <- read.csv("data/feeding_station_south_coordinates.xlsx - Sheet1.csv")
head(feedingStations)

# Are we going to be able to join these by name? I am not optimistic...
feedEvents$feeding_station %in% feedingStations$Feeding_station # awesome!!! oh my gosh.

# okay, let's join the coordinates
feedEvents <- feedEvents %>%
  left_join(feedingStations %>%
              dplyr::select(Feeding_station, lat, long),
            by = c("feeding_station" = "Feeding_station")) %>%
  mutate(lat = as.numeric(lat),
         long = as.numeric(long))

head(feedEvents)


# Remove any missing values. Later, will need to ask Gideon why these coordinates are missing, and see what we can do about it. But for now, this is just a proof of concept.
feedEvents <- feedEvents %>%
  filter(!is.na(lat) & !is.na(long))

# Now make it an sf object
feedEvents <- feedEvents %>%
  sf::st_as_sf(., coords = c("long", "lat"), remove = FALSE) %>%
  sf::st_set_crs("WGS84") %>%
  dplyr::select(-c(death_of_carcass_known, hours_since_death, origin_carcass, ranger, remarks))
```

```{r}
# Mask the data
mask <- suppressMessages(sf::st_read("data/CutOffRegion.kml"))
# datMasked <- vultureUtils::maskData(dataset = datAnnot, mask = mask, longCol = "location_long.1", latCol = "location_lat.1", crs = "WGS84")
# save(datMasked, file = "data/datMasked.Rda")
load("data/datMasked.Rda")
```

### Distance from carcass vs. time

In the supplementary material of Harel et al. 2016, it says that carcasses are usually discovered and consumed within "a few days," and that feeding by other scavengers also contributes to this. To be conservative, I'm going to examine a 4-day period after carcass deposition, regardless of when the vultures find the carcass. So that's 96 hours.

I was going to try to animate this, but instead I'm just going to calculate distance over time and plot it. Duh.

```{r}
# Set some parameters for time lengths
maxTime <- 72
maxTimeWords <- paste(as.character(maxTime), "hours")
```

```{r results='hide',fig.keep='all'}
# Make a list of the datasets for each feeding event, ranging from 2 hours before carcass placement through `maxTime` hours after carcass placement. For each point in the dataset, calculate the distance from the carcass.
eventsList <- feedEvents %>%
  group_by(datetime) %>%
  group_split(.keep = T)
length(eventsList)

# eventsDat <- map(eventsList, ~datMasked %>%
#                    # from 2 hours before the carcass was placed to maxTime hours after
#                    filter(timestamp > .x$datetime[1]-lubridate::as.duration("2 hours") & timestamp < .x$datetime[1] + lubridate::as.duration(maxTimeWords)) %>%
#                    mutate(hoursSinceCarcassPlaced = as.numeric(timestamp - .x$datetime[1], units = "hours")))
# 
# eventsDat <- map2(eventsDat, eventsList, ~{.x %>%
#     mutate(kmFromCarcass = as.numeric(sf::st_distance(., .y))/1000)})
# 
# # download elevation rasters for points within 3km of each feeding event
# eventsDat3km <- map(eventsDat, ~.x %>% filter(kmFromCarcass < 3))

# elevRasters <- map(eventsDat3km, ~{
#   if(nrow(.x) == 0){
#     return(NULL)
#   }else{
#     elev <- elevatr::get_elev_raster(.x, z = 10)
#     return(elev)
#   }
# })
# save(elevRasters, file = "data/elevRasters.Rda")
# load("data/elevRasters.Rda")
# 
# # add elevation information to data frames, only for the points within 3km of the feeding site.
# eventsDat <- map2(eventsDat, elevRasters, ~{
#   if(is.null(.y)){
#     .x <- .x %>%
#       mutate(groundElev = NA,
#              height_above_ground = NA)
#   }else{
#     .x <- .x %>%
#       mutate(groundElev = raster::extract(.y, .x),
#              height_above_ground = height_above_msl - groundElev) %>%
#       mutate(height_above_ground = case_when(height_above_ground < 0 ~ 0,
#                                              TRUE ~ height_above_ground))
#   }
# })
# 
# # Remove geometry information so the data are easier to work with
# eventsDat <- map(eventsDat, sf::st_drop_geometry)
# save(eventsDat, file = "data/eventsDat.Rda")
load("data/eventsDat.Rda")

# Now we can use this to make the same plot for each feeding event, limiting it to a certain radius
# maxTime plots
plotsMax <- map2(eventsDat, eventsList, ~{
  .x %>%
    ggplot()+
    geom_point(aes(x = timestamp, y = kmFromCarcass, col = trackId))+
    geom_line(aes(x = timestamp, y = kmFromCarcass, col = trackId))+
    geom_vline(aes(xintercept = .y$datetime[1]))+
    theme_minimal()+
    ylim(0, 5)+
    theme(legend.position = "none")
})

suppressWarnings(walk(plotsMax, print)) # have to suppress warnings because a lot of data will be cut off and ggplot will get loud about it. And no, I can't just filter the data beforehand, because then geom_line will join the points together instead of running them off the page. Trust me, I've throught this one through.

# Based on looking at this, pick just a few feeding events to view. This will make the rest of the code run faster.
toView <- c(7, 9, 11, 21, 25, 36)
suppressWarnings(walk2(plotsMax[toView], toView, ~print(.x + ggtitle(paste("Feeding event #", .y)))))
```

Same plots, but colored by elevation above the ground instead of by individual vulture:

```{r}
plotsElev <- map2(eventsDat, eventsList, ~{
  .x %>%
    ggplot()+
    geom_line(aes(x = timestamp, y = kmFromCarcass, group = trackId), alpha = 0.3)+
    geom_point(aes(x = timestamp, y = kmFromCarcass, col = height_above_ground))+
    scale_color_viridis_c()+
    geom_vline(aes(xintercept = .y$datetime[1]))+
    theme_minimal()+
    ylim(0, 5)
})

suppressWarnings(walk2(plotsElev[toView], toView, ~print(.x + ggtitle(paste("Feeding event #", .y)))))
```

```{r}
# 48 hour plots
plots48 <- map2(eventsDat, eventsList, ~{
  .x %>%
    filter(hoursSinceCarcassPlaced < 48) %>%
    ggplot()+
    geom_point(aes(x = timestamp, y = kmFromCarcass, col = trackId))+
    geom_line(aes(x = timestamp, y = kmFromCarcass, col = trackId))+
    geom_vline(aes(xintercept = .y$datetime[1]))+
    theme_minimal()+
    ylim(0, 5)+
    theme(legend.position = "none")
})

suppressWarnings(walk2(plots48[toView], toView, ~print(.x + ggtitle(paste("Feeding event #", .y)))))
```

```{r}
# 24 hour plots
plots24 <- map2(eventsDat, eventsList, ~{
  .x %>%
    filter(hoursSinceCarcassPlaced < 24) %>%
    ggplot()+
    geom_point(aes(x = timestamp, y = kmFromCarcass, col = trackId))+
    geom_line(aes(x = timestamp, y = kmFromCarcass, col = trackId))+
    geom_vline(aes(xintercept = .y$datetime[1]))+
    theme_minimal()+
    ylim(0, 5)+
    theme(legend.position = "none")
})

suppressWarnings(walk2(plots24[toView], toView, ~print(.x + ggtitle(paste("Feeding event #", .y)))))
```

Hourly averages:

```{r}
hourlyAvgs <- map(eventsDat, ~{.x %>%
    mutate(hour = floor(hoursSinceCarcassPlaced)) %>%
    group_by(trackId, hour) %>%
    summarize(kmFromCarcassHour = mean(kmFromCarcass, na.rm = T), .groups = "keep") %>%
    ungroup()})
```

```{r}
# 48 hour plots with hourly average distances
plots48_hourly <- map2(hourlyAvgs, eventsList, ~{
  .x %>%
    filter(hour < 48) %>%
    ggplot()+
    geom_point(aes(x = hour, y = kmFromCarcassHour, col = trackId))+
    geom_line(aes(x = hour, y = kmFromCarcassHour, col = trackId))+
    geom_vline(aes(xintercept = 0))+
    theme_minimal()+
    ylim(0, 5)+
    theme(legend.position = "none")+
    ggtitle(paste0("Carcass deposited: ", .y$datetime))
})

suppressWarnings(walk2(plots48_hourly[toView], toView, ~print(.x + ggtitle(paste("Feeding event #", .y)))))
```

### Detections and arrivals

1.  Define "detection" as a vulture passing within 1km of the site, regardless of speed or altitude.
2.  Define "arrival" as being within 0.25km with a ground speed \< 5m/s and an elevation \< 10m Calculate detections and arrivals for each bird at each carcass.

```{r}
eventsDat <- map(eventsDat, ~{.x %>%
    mutate(detection = case_when(kmFromCarcass < 1 & 
                                   hoursSinceCarcassPlaced > 0  ~ TRUE,
                                 TRUE ~ FALSE),
           visit = case_when(kmFromCarcass < 0.25 & ground_speed < 5 & 
                               !is.na(height_above_ground) & height_above_ground < 10 &
                               hoursSinceCarcassPlaced > 0 ~ TRUE,
                             TRUE ~ FALSE))})
```

### Latency

```{r include = F}
allCarcasses <- data.table::rbindlist(eventsDat, idcol = "eventID") %>%
  as.data.frame() %>%
  dplyr::select(eventID, ground_speed, height_above_msl, location_lat, location_long, timestamp, dateOnly, trackId, hoursSinceCarcassPlaced, kmFromCarcass, groundElev, height_above_ground, detection, visit)
```

#### Time to first detection

```{r}
firstDetections <- allCarcasses %>%
  filter(hoursSinceCarcassPlaced > 0 & hoursSinceCarcassPlaced < maxTime, 
         detection == TRUE) %>%
  group_by(eventID) %>%
  arrange(timestamp, .by_group = TRUE) %>%
  slice(1)
glimpse(firstDetections)

firstDetections %>%
  ggplot(aes(x = hoursSinceCarcassPlaced))+
  geom_density(fill = "lightblue", col = "lightblue")+
  geom_vline(aes(xintercept = 24), col = "darkblue", alpha = 0.7)+
  geom_vline(aes(xintercept = 48), col = "darkblue", alpha = 0.5)+
  geom_vline(aes(xintercept = 72), col = "darkblue", alpha = 0.3)+
  geom_vline(aes(xintercept = 96), col = "darkblue", alpha = 0.1)+
  theme_classic()+
  ylab("Frequency")+
  xlab("Time to first detection (hours)")
```

#### Time to first visit

```{r}
firstVisits <- allCarcasses %>%
  filter(hoursSinceCarcassPlaced > 0 & hoursSinceCarcassPlaced < maxTime, 
         visit == TRUE) %>%
  group_by(eventID) %>%
  arrange(timestamp, .by_group = TRUE) %>%
  slice(1)
glimpse(firstVisits)

firstVisits %>%
  ggplot(aes(x = hoursSinceCarcassPlaced))+
  geom_density(fill = "#FCA18E", col = "#FCA18E")+
  geom_vline(aes(xintercept = 24), col = "darkred", alpha = 0.7)+
  geom_vline(aes(xintercept = 48), col = "darkred", alpha = 0.5)+
  geom_vline(aes(xintercept = 72), col = "darkred", alpha = 0.3)+
  geom_vline(aes(xintercept = 96), col = "darkred", alpha = 0.1)+
  theme_classic()+
  ylab("Frequency")+
  xlab("Time to first visit (hours)")
```

#### Detections and visits

```{r}
firsts <- firstDetections %>%
  mutate(type = "detection") %>%
  bind_rows(firstVisits %>% mutate(type = "visit")) %>%
  dplyr::select(eventID, hoursSinceCarcassPlaced, type) %>%
  pivot_wider(id_cols = eventID, names_from = type, values_from = hoursSinceCarcassPlaced) %>%
  mutate(latency = visit-detection)
```

Is there a relationship between first detection and first visit? This should be intuitively obvious.

```{r}
firsts %>%
  filter(detection < maxTime) %>%
  filter(!is.na(detection) & !is.na(visit)) %>%
  ggplot(aes(x = detection, y = visit))+
  geom_point(size = 2)+
  theme_classic()+
  geom_smooth(method = "lm")
```

What is the relationship when we remove the 0 latencies?

```{r}
firsts %>%
  filter(detection < maxTime, latency > 0) %>%
  filter(!is.na(detection) & !is.na(visit)) %>%
  ggplot(aes(x = detection, y = visit))+
  geom_point(size = 2)+
  theme_classic()+
  xlab("Time to first detection (hours)")+
  ylab("Time to first visit (hours)")+
  geom_smooth(method = "lm")
```

If anything, even more straightforward!

Do later-detected carcasses take longer to be visited after detection?

```{r}
firsts %>%
  filter(detection < maxTime, latency > 0) %>%
  filter(!is.na(detection) & !is.na(visit)) %>%
  ggplot(aes(x = detection, y = latency))+
  geom_point(size = 2)+
  theme_classic()+
  ylab("Visit latency (hours)")+
  xlab("Time to first detection (hours)")+
  geom_smooth(method = "lm")
```

No relationship here. Later-detected carcasses don't take longer to be visited once they are detected. That said, the sample size is really small--need more data.

### Accumulation curves: birds at carcasses

Group by carcass and individual to get each bird's first visit.

```{r}
firstVisits <- allCarcasses %>%
  group_by(eventID, trackId) %>%
  filter(visit == TRUE) %>%
  arrange(timestamp, .by_group = TRUE) %>%
  slice(1) 

firstVisits <- firstVisits %>%
  group_by(eventID) %>%
  arrange(timestamp, .by_group = T) %>%
  mutate(nFirstVisits = 1:n()) # how many individual vultures visited the carcass?
```

Plot accumulation curves

```{r}
# Absolute
firstVisits %>%
  ggplot(aes(x = hoursSinceCarcassPlaced, y = nFirstVisits, 
             col = as.factor(eventID)))+       
  geom_line()+
  theme_classic()+
  theme(legend.position = "none")+
  ylab("Number of unique vultures that have visited")+
  xlab("Time since carcass placement (hours)")

# Relative
firstVisits <- firstVisits %>%
  group_by(eventID) %>%
  arrange(timestamp, .by_group = TRUE) %>%
  mutate(timeSinceFirstVisit = timestamp-timestamp[1])

firstVisits %>%
  filter(as.numeric(timeSinceFirstVisit)/3600 < maxTime) %>%
  ggplot(aes(x = as.numeric(timeSinceFirstVisit)/3600, y = nFirstVisits, 
             col = as.factor(eventID)))+       
  geom_line()+
  theme_classic()+
  theme(legend.position = "none")+
  ylab("Number of unique vultures that have visited")+
  xlab("Time since the first vulture first visited (hours)")
```

## ANIMATION

I'm going to be following this tutorial: <https://hansenjohnson.org/post/animate-movement-in-r/> Make an animation for a single carcass over a few days. I'm going to use feeding event 36, since it seems relatively simple.

### STEP 1:

```{r}
# get basemap data
bg = ne_countries(country = c("israel", "palestine"), returnclass = "sf")

# eventsDat already excludes individuals outside of Israel, so I'm going to just pull from eventsDat.
# simplify the data
whichEvent <- 36
simple <- eventsDat[[whichEvent]] %>%
  dplyr::select(trackId, ground_speed, location_lat, location_long, hoursSinceCarcassPlaced, kmFromCarcass, height_above_ground, detection, visit)
```

### STEP 2: Process the data

```{r}
# For the animation to work, we have to have these fixes taken at regular intervals. That also means we have to fill in the blank intervals.

# For now, I'm going to aggregate the fixes to every hour. Eventually might want to do every minute (we definitely don't need the seconds).
hours <- simple %>%
  mutate(hour = floor(hoursSinceCarcassPlaced))

# compute hourly average positions and speeds
hours <- hours %>%
  sf::st_drop_geometry() %>%
  group_by(trackId, hour) %>%
  summarize(lat = mean(location_lat, na.rm = T),
            long = mean(location_long, na.rm = T),
            speed = mean(ground_speed, na.rm = T),
            dist = mean(kmFromCarcass, na.rm = T)) %>%
  ungroup() %>%
  distinct()

# create 'ideal' data with all combinations of data
ideal = expand_grid(
  trackId = unique(hours$trackId),
  hour = seq(from = min(hours$hour), to = max(hours$hour))
)

# create complete dataset
df_all <- left_join(ideal, hours) %>%
  arrange(trackId, hour)

# fill in missing data so that the birds stay in place instead of disappearing
df_all <- df_all %>%
  mutate(filled = ifelse(is.na(lat) | is.na(long), T, F)) %>%
  group_by(trackId) %>%
  arrange(hour, .by_group = T) %>%
  fill(c(lat, long, speed, dist), .direction = "down") %>%
  ungroup()
df_all

# Any distances > 20km, set to NA
df_all$lat[df_all$dist > 20] <- NA
df_all$long[df_all$dist > 20] <- NA
df_all$dist[df_all$dist > 20] <- NA
```

### STEP 3: Make the plot

```{r}
carcassSite <- eventsList %>% pluck(whichEvent) %>%
  dplyr::select(lat, long) %>%
  as.vector() %>% as.numeric()
bbox <- bboxFromRad(lon = carcassSite[2], lat = carcassSite[1], kmDist = 20)
p <- ggplot()+
  geom_sf()+
  coord_sf(xlim = bbox$xlims, 
           ylim = bbox$ylims, 
           expand = FALSE)+
  # lines and points
  geom_path(data = df_all, 
            aes(x = long, y = lat, group = trackId, color = trackId), 
            alpha = 0.3, size = 0.5)+
  geom_point(data = df_all, 
             aes(x = long, y = lat, group = trackId, color = trackId),
             alpha = 0.7, size = 2)+
  #scale_color_manual(values = colors)+
  labs(x = NULL, y = NULL)+
  theme(panel.grid = element_blank(),
        legend.position = "none")+
  NULL
p
```

### STEP 4: Make the animation

```{r eval = FALSE}
anim <- p + 
  transition_reveal(along = hour)+
  ease_aes('linear')+
  ggtitle("Hour: {frame_along}")

gganimate::animate(anim, nframes = length(unique(df_all$hour)), fps = 10) # XXX error here--come back to this.
gganimate::anim_save("data/carcassAnimation.gif", anim)
```

Okay, I would have to tweak this animation a lot more in order to really show them arriving at a carcass, I think.

## ARRIVAL ORDER at known carcasses

### Visits

```{r}
# Get just an ordered list of who detected the carcass first in the first 96 hours since the carcass was deposited
visitOrders <- allCarcasses %>%
  filter(hoursSinceCarcassPlaced <= 96) %>%
  dplyr::select(eventID, trackId, timestamp, hoursSinceCarcassPlaced, kmFromCarcass, visit) %>%
  distinct() %>%
  filter(visit == TRUE) %>%
  group_by(eventID) %>%
  arrange(timestamp, .by_group = T) %>%
  group_split(.keep = T) %>%
  map_dfr(~.x %>% select(trackId, eventID))

# Remove repeated elements in a row
visitOrders_noRepeats <- visitOrders %>%
  group_by(eventID) %>%
  distinct() %>%
  mutate(order = 1:n(),
         type = "visit")
```

### Detections

Now we can do the same thing for detections (including detections that are also visits--they're nested)

```{r}
# Get just an ordered list of who detected the carcass first in the first 96 hours since the carcass was deposited
detectionOrders <- allCarcasses %>%
  filter(hoursSinceCarcassPlaced <= 96) %>%
  dplyr::select(eventID, trackId, timestamp, hoursSinceCarcassPlaced, kmFromCarcass, detection, visit) %>%
  distinct() %>%
  filter(detection == TRUE) %>%
  group_by(eventID) %>%
  arrange(timestamp, .by_group = T) %>%
  group_split(.keep = T) %>%
  map_dfr(~.x %>% select(trackId, eventID))

# Remove repeated elements in a row
detectionOrders_noRepeats <- detectionOrders %>%
  group_by(eventID) %>%
  distinct() %>%
  mutate(order = 1:n(),
         type = "detection")
```

### Compare visits vs. detections

```{r include = F}
# SANITY CHECK
dfCombined <- bind_rows(detectionOrders_noRepeats, visitOrders_noRepeats) %>%
  pivot_wider(names_from = "type", names_prefix = "order_", values_from = "order", id_cols = c(trackId, eventID)) # important to join this way, not the opposite way

dfCombined %>%
  filter(is.na(order_detection)) # good, there are no NA's in order_detection

dfCombined %>%
  filter(is.na(order_visit)) # to be expected, there are some NA's in order_visit
```

```{r}
# Does detection rank order correlate with visit rank order?
dfCombined %>% # XXX COME BACK TO THIS--NEED TO FILTER OUT THE DETECTIONS THAT ARE ALSO VISITS
  ggplot(aes(x = order_detection, y = order_visit, col = factor(eventID)))+
  geom_point(alpha = 0.5, size = 2)+
  geom_smooth(method = "lm", se = F, size = 0.5)+
  theme_minimal()+
  ylab("Rank order (visits)")+
  xlab("Rank order (detections)")+
  theme(legend.position = "none")
```

There is usually a relationship between detections and visits--i.e. those that detect the carcass later are also later to visit. But this isn't always the case--in a few cases, there seems to be a negative relationship (those that first detect the carcass visit later than those that detect it later.)

## DEFINE TIME SCALES FOR BEHAVIORAL CONTEXTS

What is the time scale over which we can make a network such that 90% of the individuals that fed at the carcass are included in the largest connected component?

The context here is that if we want to run a diffusion analysis, we have to determine which network to run it ON. The actual running of the procedure is pretty straightforward. Different timescales may be meaningful for information transmission in different behavioral contexts. So let's determine which timescale is meaningful for each one.

Pseudocode:

```{r}
# before map:
roostPolygons <- sf::st_read("data/AllRoostPolygons.kml")
getIndivsInLCC <- function(graph){
  # get components of the graph
  components <- igraph::clusters(graph, mode="weak")
  
  # get largest connected component
  biggest_cluster_id <- which.max(components$csize)
  
  # ids
  vert_ids <- names(V(graph)[components$membership == biggest_cluster_id])
}
#######################

# For each feeding event:
days <- 50
daysBack <- seq(from = 1, to = days, by = floor(days/10))
names(daysBack) <- as.character(daysBack)
whichEvent <- 6
dateTime <- eventsList[[whichEvent]]$datetime[1]

# 1. Define "fed at the carcass" as "made a **visit** to the carcass during the `r maxTime` hour window starting when it was initially placed. 
# - Defining "visit" same as above in the script (definition subject to change). 
# - Defining `maxTime` same as above: right now it's `r maxTime` hours.
# 
# 2.  Get a list of individuals that visited the carcass for each feeding event, according to that definition. Call this `participants`. Call the list `participantsList` or something.
# Get participants
if(whichEvent %in% visitOrders_noRepeats$eventID){
  participants <- visitOrders_noRepeats %>%
    filter(eventID == whichEvent) %>%
    pull(trackId)
}else{
  participants <- NA
}

# Get prior data
priorData <- datMasked %>%
  # from 1 month before the carcass was placed until the day it was placed
  filter(timestamp > lubridate::as_date(dateTime)-lubridate::as.duration(paste(days, "days")) & 
           timestamp <= lubridate::as_date(dateTime)) %>%
  mutate(hoursBeforeCarcassPlaced = as.numeric(timestamp - dateTime, units = "hours"))

# Get initial visit and initial detection
idd <- firstDetections %>%
  filter(eventID == whichEvent) %>%
  pull(timestamp) %>%
  first()

ivd <- firstVisits %>%
  filter(eventID == whichEvent) %>%
  pull(timestamp) %>%
  first()

# Create feeding and flying edges
flightEdges <- vultureUtils::getFlightEdges(dataset = priorData, 
                                            roostPolygons = roostPolygons, 
                                            roostBuffer = 50, 
                                            consecThreshold = 2, 
                                            distThreshold = 250) %>%
  mutate(minDate = lubridate::as_date(minTimestamp),
         maxDate = lubridate::as_date(maxTimestamp))

feedingEdges <- vultureUtils::getFeedingEdges(dataset = priorData, 
                                              roostPolygons = roostPolygons,
                                              roostBuffer = 50, 
                                              consecThreshold = 2) %>%
  mutate(minDate = lubridate::as_date(minTimestamp),
         maxDate = lubridate::as_date(maxTimestamp))

# For the edge lists, define how many days before the IVD each interaction occurred. Going to base this on the maxDate, just in case any span midnight.
flightEdges <- flightEdges %>%
  mutate(daysBeforeIVD = as.numeric(lubridate::as_date(ivd) - maxDate))

feedingEdges <- feedingEdges %>%
  mutate(daysBeforeIVD = as.numeric(lubridate::as_date(ivd) - maxDate))

# Working backwards from the IVD, split each edge list into smaller, nested edge lists, ranging in length from 1 day to `days` days long.
flightEdges_nested <- map(daysBack, ~flightEdges %>%
                            filter(daysBeforeIVD <= .x) %>%
                            mutate(daysBack = .x))
feedingEdges_nested <- map(daysBack, ~feedingEdges %>%
                             filter(daysBeforeIVD <= .x) %>%
                             mutate(daysBack = .x))

# Make networks!
flightEdges_graphs <- vultureUtils::makeGraphsList(flightEdges_nested)$graphs
feedingEdges_graphs <- vultureUtils::makeGraphsList(feedingEdges_nested)$graphs

# Extract number of days for each, from the names
nDays_flight <- as.numeric(names(flightEdges_graphs))
nDays_feeding <- as.numeric(names(feedingEdges_graphs))

# For each network, get a list of the individuals present in the largest connected component.
indivsInLCC_flight <- map(flightEdges_graphs, getIndivsInLCC)
indivsInLCC_feeding <- map(feedingEdges_graphs, getIndivsInLCC)

# (Get number of individuals in the largest connected component, in case we need to use this later)
nIndivsInLCC_flight <- map_dbl(indivsInLCC_flight, length)
nIndivsInLCC_feeding <- map_dbl(indivsInLCC_feeding, length)

# How many participants are included?
propIncluded_flight <- map_dbl(indivsInLCC_flight, ~{
  howManyIncluded <- participants %in% .x %>% sum()
  return(howManyIncluded/length(participants))
  }) %>%
  as.data.frame() %>%
  setNames(., "propIncluded_flight") %>%
  mutate(daysBack = nDays_flight)

propIncluded_feeding <- map_dbl(indivsInLCC_feeding, ~{
  howManyIncluded <- participants %in% .x %>% sum()
  return(howManyIncluded/length(participants))
  }) %>%
  as.data.frame() %>%
  setNames(., "propIncluded_feeding") %>%
  mutate(daysBack = nDays_feeding)

# Combine the two, and add the eventID
out <- left_join(propIncluded_flight, propIncluded_feeding, by = "daysBack") %>%
  mutate(eventID = whichEvent) %>%
  dplyr::select(eventID, daysBack, propIncluded_flight, propIncluded_feeding)

# Fix up the data frame: if there are no participants, or if there are no individuals included in the LCC, change 0's to NA's.
if(length(participants) == 1 & all(is.na(participants))){
  out <- out %>%
    mutate(propIncluded_flight = NA,
           propIncluded_feeding = NA)
}else if(map_lgl(indivsInLCC_feeding, is.null) %>% any() | map_lgl(indivsInLCC_flight, is.null) %>% any()){
  if(map_lgl(indivsInLCC_feeding, is.null) %>% any()){
    whichFeedToNA <- unname(which(map_lgl(indivsInLCC_feeding, is.null)))
    out$propIncluded_feeding[whichFeedToNA] <- NA
  }
  if(map_lgl(indivsInLCC_flight, is.null) %>% any()){
    whichFlightToNA <- unname(which(map_lgl(indivsInLCC_flight, is.null)))
    out$propIncluded_flight[whichFlightToNA] <- NA
  }
}

outList <- list("propData" = out,
                "participants" = participants)
```
