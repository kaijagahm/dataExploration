---
title: "Roost classifications"
format: html
editor: source
execute: 
  echo: false  
  cache: true
---

After incorporating Marta's roost assignment code into my vultureUtils package, I pulled roost locations for the cleaned data between 2020 and 2022. As a follow-up to what we discussed in the last vulture meeting, I started playing around with some clustering methods to see what might be best for making reasonable roost assignments.

```{r}
library(vultureUtils)
library(tidyverse)
library(gganimate)
library(dendextend)
library(sf)
library(fpc)
library(paletteer)
library(leaflet)
```

```{r}
load("data/datAnnotCleaned.Rda")
roostPolygons <- sf::st_read("data/AllRoostPolygons.kml") %>%
  sf::st_set_crs("WGS84")
```

```{r}
#| output: false

# Get roost data for the entire dataset.
# roosts <- vultureUtils::get_roosts_df(df = datAnnotCleaned, id = "trackId")
# feather::write_feather(roosts, "data/roosts.feather")
roosts <- feather::read_feather("data/roosts.feather")
simplifiedRoosts <- roosts %>%
  dplyr::select(trackId, location_long, location_lat, roost_date)%>%
  sf::st_as_sf(coords = c("location_long", "location_lat"), remove = F) %>%
  sf::st_set_crs("WGS84")

# Crop the roost polygons to the extent of the roost locations
croppedRoostPolygons <- st_crop(roostPolygons, xmin = min(simplifiedRoosts$location_long), xmax = max(simplifiedRoosts$location_long), ymin = min(simplifiedRoosts$location_lat), ymax = max(simplifiedRoosts$location_lat))
```

Here's what it looks like if we plot all of the roost locations. Marta has already done this.

```{r}
ggplot(simplifiedRoosts, alpha = 0.2)+
  geom_sf()+
  geom_sf(data = croppedRoostPolygons, fill = NA, col = "red")+
  theme_classic()+
  theme(legend.position = "none")+
  ggtitle("All roost locations, 2020-2022")
```

What if we facet by year? At first glance, do the roost locations look different from year to year?

```{r}
simplifiedRoosts <- simplifiedRoosts %>%
  mutate(year = lubridate::year(roost_date))

years <- simplifiedRoosts %>%
  group_by(year) %>%
  group_split(.keep = T)

ggplot(simplifiedRoosts, alpha = 0.2)+
  geom_sf()+
  geom_sf(data = croppedRoostPolygons, fill = NA, col = "red")+
  theme_classic()+
  theme(legend.position = "none")+
  ggtitle("All roost locations, 2020-2022")+
  facet_wrap(~year)
```

While there are some new/different roosts in each year, on the whole the vultures seem to be using the same main roosts from year to year. This tracks with what we know about their habits, so it's reassuring to see it reflected in the data.

Because I wanted to make a compelling visual (and learn gganimate along the way!) I made this gif. It shows roost sites over time. Each frame of the gif is a single day, from the beginning of the dataset to the present. Colored points are where individuals roosted on that day. The small gray transparent points in the background are past roost sites--they accumulate as the gif progresses. The colored points are colored by year, so they change color as the gif progresses.

```{r}
anim <- simplifiedRoosts %>%
  mutate(time = as.numeric(factor(roost_date))) %>%
  ggplot(.)+
  geom_sf(size = 5, aes(col = factor(year)))+
  scale_color_brewer(name = "Year", palette = "Dark2")+
  geom_sf(data = croppedRoostPolygons, fill = NA, col = "blue")+
  theme_classic()+
  transition_time(time)+
  shadow_mark(color = "black", alpha = 0.1, size = 1)+
  ggtitle("Roost locations over time")

animate(anim, fps = 4)
anim_save("data/roostLocations.gif", anim)
```

I don't think this tells us anything particularly revolutionary, but it's cool to be able to see the roosting in "real time!"

## K-means clustering

At our meeting, Noa suggested using k-means clustering to assign roost sites. I don't think this is the right method, but it's easily tractable, so I decided to start by giving it a shot.

Arbitrarily, let's start with 50 clusters. Here's what the results look like.

```{r}
roostLocs <- simplifiedRoosts %>%
  dplyr::select(location_long, location_lat) %>%
  sf::st_drop_geometry()
clusters <- kmeans(x = roostLocs, centers = 50)
centers <- clusters$centers
assignments <- clusters$cluster

simplifiedRoosts <- simplifiedRoosts %>%
  mutate(cluster = assignments)
```

```{r}
ggplot(simplifiedRoosts, alpha = 0.5)+
  geom_sf(aes(col = factor(cluster)))+
  geom_sf(data = croppedRoostPolygons, fill = NA, col = "black")+
  theme_classic()+
  theme(legend.position = "none")+
  scale_color_paletteer_d("ggsci::default_igv")
```

Okay, we could do k-means clustering with any arbitrary number and get some result. But I'm not sure how meaningful that is. My biggest gripe with this is that it takes all of the various scattered roosts and forces them to be grouped with others. This gives us really diffuse clusters that aren't biologically meaningful. Ideally, we'd want to count those as their own roosts.

If we want to obtain many more than 50 clusters and allow some to have isolated points, we could try increasing k. But I think that will tend to break up the large central clusters artificially before it will have much of an effect on the outlying points.

Next, I decided to try hierarchical clustering, which can deal a bit more easily with large numbers of clusters and/or clusters containing very few points.

## Try hierarchical clustering

```{r}
?distm # default unit here is meters, which is what we want!
testDF <- bind_rows(years[[1]], years[[2]], years[[3]]) %>%
  sf::st_as_sf(coords = c("location_long", "location_lat"), remove = F) %>%
  sf::st_set_crs("WGS84")

# # Compute pairwise distances between points
# distanceMatrix <- sf::st_distance(testDF, testDF) %>% as.dist() # this takes a really really long time with such a big dataset.
# save(distanceMatrix, file = "data/distanceMatrix.Rda")
load("data/distanceMatrix.Rda")
```

```{r}
# Do clustering
clust <- hclust(d = distanceMatrix, method = "complete")
plot(clust, labels = F)

# We can cut the dendrogram based on either number of clusters or on the distance between points.
# Cut the dendrogram into different numbers of clusters
numberCuts <- as.data.frame(cutree(clust, k = c(50, 60, 70, 80, 90)))
names(numberCuts) <- paste0("k_", names(numberCuts))

# Alternatively, cut the dendrogram based on different distances
distanceCuts <- as.data.frame(cutree(clust, h = c(50, 100, 150, 200, 250,  300, 500, 1000)))
names(distanceCuts) <- paste0("dist_", names(distanceCuts))

# Create a data frame
testDF_withClusters <- bind_cols(testDF, numberCuts, distanceCuts)
```

Hierarchical clustering creates a dendrogram, shown above. Note that this dendrogram is created with complete linkage. There are many other methods we could have used; I picked complete just to test it out. I played around with other methods, and they gave trees that looked a bit different, but none of them produced adequate clusters (I'll show below for complete linkage why I'm not satisfied with these clusters).

Once we have this dendrogram, we can "cut" the tree into clusters in order to assign each point to a cluster. We can do that cutting in two ways. Either we can tell R how many clusters we'd like to end up with and it will find the height at which to cut the tree in order to produce that many clusters, or we can tell R that we want to cut at a specific height (i.e. a specific distance between any given pair of points) and accept however many clusters are produced by that cut. The latter is perhaps easier to justify with biology, but I tried both.

Here are some examples of how the clustering looks if I cut the tree to a set number of clusters.

```{r layout-ncol=2}
plots_numbers <- map(names(testDF_withClusters)[grepl("k_", names(testDF_withClusters))], ~{
  n <- str_extract(.x, "[0-9]+")
  p <- ggplot(data = testDF_withClusters)+
  geom_sf(aes(col = as.factor(.data[[.x]])), alpha = 0.5)+
  geom_sf(data = croppedRoostPolygons, fill = NA)+
  theme_classic()+
  theme(legend.position = "none", panel.grid = element_blank())+
  ggtitle(paste0("Number of clusters = ", n))
})
walk(plots_numbers, print)
```

And here's what it looks like if I make plots based on the distance between points.

```{r layout-ncol=2}
plots_distances <- map(names(testDF_withClusters)[grepl("dist_", names(testDF_withClusters))], ~{
  dist <- str_extract(.x, "[0-9]+")
  ggplot(data = testDF_withClusters)+
    geom_sf(aes(col = as.factor(.data[[.x]])), alpha = 0.5)+
    geom_sf(data = croppedRoostPolygons, fill = NA)+
    theme_classic()+
    theme(legend.position = "none", panel.grid = element_blank())+
    ggtitle(paste0("Distance = ", dist))
})
walk(plots_distances, print)
```

These plots aren't very meaningful, because there are so many clusters that the map can't handle plotting them each in a different color.

That raises a very natural next question: If we cut the tree based on distances, how many clusters do we end up with?

```{r}
# number of clusters
dists <- seq(100, 2000, by = 100)
testDistanceCuts <- as.data.frame(cutree(clust, h = dists))
nClusters <- map_dbl(testDistanceCuts, max)
plot(nClusters~dists, type = "o", pch = 19)

# This is not particularly helpful for selecting the distance. I suppose we could look at the elbow, which is a bit lower than 500m. 1000m seems like a potentially relevant distance, though, so I'm going to go with that for now, I guess? Note that even at a distance of 1000, we still get about 500 unique roosts.
```

There does seem to be something of an elbow a bit under 500, say around 350m? But it's not crystal clear. If we decided to pick, say, 350m as our cut distance, we would end up with a little less than 1000 clusters, and we would still have quite a few outlying points grouped together.

Instead of paying attention to those outlying points, though, let's zoom in for a moment on our known roost sites, the craters.

```{r layout-ncol=2}
# crop the roost polygons
ymax <- 31.2
ymin <- 30.6
xmax <- 35.3
xmin <- 34.75

plots_numbers_zoomed <- map(names(testDF_withClusters)[grepl("k_", names(testDF_withClusters))], ~{
  n <- str_extract(.x, "[0-9]+")
  p <- ggplot(data = testDF_withClusters)+
    geom_sf(aes(col = as.factor(.data[[.x]])), alpha = 0.5)+
    geom_sf(data = croppedRoostPolygons, fill = NA)+
    theme_classic()+
    theme(legend.position = "none", panel.grid = element_blank())+
    ggtitle(paste0("Number of clusters = ", n))+
    ylim(ymin, ymax)+
    xlim(xmin, xmax)
})
walk(plots_numbers_zoomed, print)

plots_distances_zoomed <- map(names(testDF_withClusters)[grepl("dist_", names(testDF_withClusters))], ~{
  dist <- str_extract(.x, "[0-9]+")
  ggplot(data = testDF_withClusters)+
    geom_sf(aes(col = as.factor(.data[[.x]])), alpha = 0.5)+
    geom_sf(data = croppedRoostPolygons, fill = NA)+
    theme_classic()+
    theme(legend.position = "none", panel.grid = element_blank())+
    ggtitle(paste0("Distance = ", dist))+    
    ylim(ymin, ymax)+
    xlim(xmin, xmax)
})
walk(plots_distances_zoomed, print)

```

When we use biologically reasonable distances to cut the hierarchical clustering dendrogram, the large roost polygons still get broken up quite a bit. Even with a distance as great as 1000m, which is on the high end of what I'd want to use, we're nowhere close to allowing for clusters as large as we need (like in the crater).

## DBSCAN clustering

Next, I decided to try DBSCAN, which is a density-based algorithm that is especially well suited to weird-shaped and differently-sized clusters. There's a good explanation of how this works \[here\](https://www.youtube.com/watch?v=RDZUdRSDOok). Notably, it only needs two parameters to be specified, and they are both relatively easy to tie to biology. 1) The distance between "core points" such that they can be considered part of the same clusters, and 2) The minimum number of points to define a cluster.

DBSCAN differs notably from the other clustering algorithms in that it does not necessarily assign every single point to a cluster. After dividing the points into "core points," "border points," and "outliers," DBSCAN assigns the core and border points to clusters, but it keeps the outliers unassigned. This is effectively the same as saying that all the outliers are their own clusters of size 1. This is, I think, what we want.

So, how to choose the parameters? I chose the minimum number of core points as 3, to be very conservative. I think 3 is the smallest that makes sense, although maybe 2 would be justifiable. For the distance between points, I'll try a range of distances between 100 and 1500m.

```{r}
testDF <- testDF %>%
  sf::st_drop_geometry()

nPoints <- nrow(testDF)
dists <- c(100, 250, 500, 750, 1000, 1500)
minpts <- 3
dbscans_list <- vector(mode = "list", length = length(dists))
for(i in 1:length(dists)){
  dbscans_list[[i]] <- fpc::dbscan(distanceMatrix, eps = dists[i], method = "dist", MinPts = minpts)
}
# data_dbscans <- map(dbscans_list, ~bind_cols(testDF, "cluster" = .x$cluster) %>%
#                       mutate(isOutlier = ifelse(cluster == 0, T, F)) %>%
#                       sf::st_as_sf(coords = c("location_long", "location_lat"), remove = F) %>%
#                       sf::st_set_crs("WGS84"))
# save(data_dbscans, file = "data/data_dbscans.Rda")
load("data/data_dbscans.Rda")

nOutliers <- map_dbl(data_dbscans, ~.x %>%
                       filter(cluster == 0) %>%
                       nrow())
outliers <- data.frame(dist = dists, 
                       nOutliers = nOutliers,
                       propOutliers = nOutliers/nPoints)

outliers %>%
  ggplot(aes(x = dist, y = propOutliers))+
  geom_point(size = 2)+
  geom_line()+
  theme_classic()+
  ylab("Proportion of points not included in a cluster")+
  xlab("Neighborhood distance (m)")
```

The distance graph has a similar shape to the one I got from the hierarchical clustering, and once again the elbow seems to be somewhere around 350 or 400m.

Let's take a look at the cluster results for each distance. Note that the + signs are outliers (i.e. their own cluster, or not assigned to any cluster.

```{r}
set.seed(1)
zoomPlots <- map2(data_dbscans, dists, ~{
  yr <- min(lubridate::year(.x$roost_date))
  ggplot(data = .x %>% filter(cluster != 0))+
    geom_sf(aes(col = as.factor(cluster), alpha = 0.5))+
    geom_sf(data = .x %>% filter(cluster == 0), alpha = 0.7, pch = 3)+
    geom_sf(data = croppedRoostPolygons, fill = NA)+
    theme_classic()+
    theme(legend.position = "none", panel.grid = element_blank())+
    ggtitle(paste0("Distance = ", .y))+    
    ylim(ymin, ymax)+
    xlim(xmin, xmax)
})

walk(zoomPlots, print)
```

Some thoughts and reflections on these results:

1.  A distance of around 500 or 750 seems to get reasonable results for many of the clusters without completely overwhelming everything with outliers.
2.  That said, there are still many clusters that cover multiple roost polygons. There are also many roost polygons that include points assigned to several different clusters.
3.  Possible next steps:
    1.  Test a range of values for the minimum number of core points included in a cluster. 3 is pretty low already, and I have a feeling that increasing the number would make the above problems worse, not better. But what about trying 2 or 4?

    2.  Secondarily cluster the outliers using hierarchical or k-means clustering. If we do this, it would be important to note that the two types of clusters don't represent the same conceptual thing. Clustering the outliers would just be saying "okay, of these points that don't fall into an official 'roost site', what regions can they be grouped into?"

    3.  Consider which problems are top priority to solve. We can already see conflicting priorities here, where some polygons include points assigned to multiple clusters and other clusters aren't fully captured by a single polygon. Is one of these outcomes more problematic than the other? Are there cases where we have reason to doubt the polygons? If the points are telling us that it's not really possible to carve up a given site into distinct roosts because the birds roost so frequently in between the polygons, what do we do with that information? How much do we care about the huge number of outliers--can we take those as face value and just say that it's relatively frequent for birds to roost away from a known "roost site"?

    4.  Add more environmental variables to cluster on, in addition to latitude/longitude. The roost polygons were drawn taking into account sight lines, elevation, etc. So it's possible that adding a DEM, or directly computing a raster of sight lines, would allow us to do a multivariate clustering and would give us more reasonable results. Then again, we should think carefully about #3 first--this would be a lot of extra effort. Is it worth it?

I hope this is helpful! Feel free to make any suggestions or changes. This isn't complete, but it's my progress so far, and maybe it will save you a bit of work if you try to do something similar.
